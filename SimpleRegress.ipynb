{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleRegress.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maximeLpt/DL_project/blob/main/SimpleRegress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "Ip_c8lXG2lV-",
        "outputId": "dd1aa0c9-4b65-42a5-f179-7c8c09a6db0f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "training_data = pd.read_csv(\"if_yoy_can_you_live.csv\")\n",
        "training_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>kpler_index</th>\n",
              "      <th>signal_high_api</th>\n",
              "      <th>signal_low_api</th>\n",
              "      <th>signal_high_sulfur</th>\n",
              "      <th>signal_low_sulfur</th>\n",
              "      <th>signal_raw</th>\n",
              "      <th>brent_m1m2</th>\n",
              "      <th>brent_m3m4</th>\n",
              "      <th>dfl</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "      <th>kpler_index_SMA_5</th>\n",
              "      <th>kpler_index_SMA_20</th>\n",
              "      <th>kpler_index_SMA_50</th>\n",
              "      <th>kpler_index_SMA_75</th>\n",
              "      <th>signal_high_api_SMA_5</th>\n",
              "      <th>signal_high_api_SMA_20</th>\n",
              "      <th>signal_high_api_SMA_50</th>\n",
              "      <th>signal_high_api_SMA_75</th>\n",
              "      <th>signal_low_api_SMA_5</th>\n",
              "      <th>signal_low_api_SMA_20</th>\n",
              "      <th>signal_low_api_SMA_50</th>\n",
              "      <th>signal_low_api_SMA_75</th>\n",
              "      <th>signal_high_sulfur_SMA_5</th>\n",
              "      <th>signal_high_sulfur_SMA_20</th>\n",
              "      <th>signal_high_sulfur_SMA_50</th>\n",
              "      <th>signal_high_sulfur_SMA_75</th>\n",
              "      <th>signal_low_sulfur_SMA_5</th>\n",
              "      <th>signal_low_sulfur_SMA_20</th>\n",
              "      <th>signal_low_sulfur_SMA_50</th>\n",
              "      <th>signal_low_sulfur_SMA_75</th>\n",
              "      <th>signal_raw_SMA_5</th>\n",
              "      <th>signal_raw_SMA_20</th>\n",
              "      <th>signal_raw_SMA_50</th>\n",
              "      <th>signal_raw_SMA_75</th>\n",
              "      <th>brent_m1m2_SMA_5</th>\n",
              "      <th>brent_m1m2_SMA_20</th>\n",
              "      <th>brent_m1m2_SMA_50</th>\n",
              "      <th>brent_m1m2_SMA_75</th>\n",
              "      <th>brent_m3m4_SMA_5</th>\n",
              "      <th>brent_m3m4_SMA_20</th>\n",
              "      <th>brent_m3m4_SMA_50</th>\n",
              "      <th>brent_m3m4_SMA_75</th>\n",
              "      <th>dfl_SMA_5</th>\n",
              "      <th>dfl_SMA_20</th>\n",
              "      <th>dfl_SMA_50</th>\n",
              "      <th>dfl_SMA_75</th>\n",
              "      <th>month_SMA_5</th>\n",
              "      <th>month_SMA_20</th>\n",
              "      <th>month_SMA_50</th>\n",
              "      <th>month_SMA_75</th>\n",
              "      <th>day_SMA_5</th>\n",
              "      <th>day_SMA_20</th>\n",
              "      <th>day_SMA_50</th>\n",
              "      <th>day_SMA_75</th>\n",
              "      <th>day_of_week_SMA_5</th>\n",
              "      <th>day_of_week_SMA_20</th>\n",
              "      <th>day_of_week_SMA_50</th>\n",
              "      <th>day_of_week_SMA_75</th>\n",
              "      <th>month_sin_SMA_5</th>\n",
              "      <th>month_sin_SMA_20</th>\n",
              "      <th>month_sin_SMA_50</th>\n",
              "      <th>month_sin_SMA_75</th>\n",
              "      <th>month_cos_SMA_5</th>\n",
              "      <th>month_cos_SMA_20</th>\n",
              "      <th>month_cos_SMA_50</th>\n",
              "      <th>month_cos_SMA_75</th>\n",
              "      <th>moving_correl_30</th>\n",
              "      <th>moving_correl_50</th>\n",
              "      <th>moving_correl_75</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-08-17</td>\n",
              "      <td>-0.148709</td>\n",
              "      <td>0.517667</td>\n",
              "      <td>-0.567917</td>\n",
              "      <td>-0.342500</td>\n",
              "      <td>0.441923</td>\n",
              "      <td>0.035185</td>\n",
              "      <td>0.31</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.262041</td>\n",
              "      <td>-0.276216</td>\n",
              "      <td>-0.379981</td>\n",
              "      <td>-0.360854</td>\n",
              "      <td>0.502600</td>\n",
              "      <td>0.455833</td>\n",
              "      <td>0.243927</td>\n",
              "      <td>0.232858</td>\n",
              "      <td>-0.683500</td>\n",
              "      <td>-0.829500</td>\n",
              "      <td>-0.906700</td>\n",
              "      <td>-0.925278</td>\n",
              "      <td>-0.463143</td>\n",
              "      <td>-0.534446</td>\n",
              "      <td>-0.655971</td>\n",
              "      <td>-0.660105</td>\n",
              "      <td>0.447769</td>\n",
              "      <td>0.335827</td>\n",
              "      <td>0.150931</td>\n",
              "      <td>0.125462</td>\n",
              "      <td>-0.024556</td>\n",
              "      <td>-0.115426</td>\n",
              "      <td>-0.267463</td>\n",
              "      <td>-0.281869</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.1398</td>\n",
              "      <td>0.239600</td>\n",
              "      <td>-0.476</td>\n",
              "      <td>-0.5345</td>\n",
              "      <td>-0.5190</td>\n",
              "      <td>-0.471867</td>\n",
              "      <td>-1.226</td>\n",
              "      <td>-1.3800</td>\n",
              "      <td>-1.3970</td>\n",
              "      <td>-1.317333</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.60</td>\n",
              "      <td>6.90</td>\n",
              "      <td>6.333333</td>\n",
              "      <td>12.8</td>\n",
              "      <td>14.70</td>\n",
              "      <td>15.06</td>\n",
              "      <td>14.906667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-7.196152e-01</td>\n",
              "      <td>-0.417846</td>\n",
              "      <td>-0.145231</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.646410</td>\n",
              "      <td>-0.823731</td>\n",
              "      <td>-0.846761</td>\n",
              "      <td>0.692622</td>\n",
              "      <td>0.052064</td>\n",
              "      <td>0.264829</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-08-18</td>\n",
              "      <td>-0.146644</td>\n",
              "      <td>0.531667</td>\n",
              "      <td>-0.538333</td>\n",
              "      <td>-0.323571</td>\n",
              "      <td>0.465000</td>\n",
              "      <td>0.056111</td>\n",
              "      <td>0.33</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.240054</td>\n",
              "      <td>-0.269423</td>\n",
              "      <td>-0.374474</td>\n",
              "      <td>-0.357109</td>\n",
              "      <td>0.502267</td>\n",
              "      <td>0.463483</td>\n",
              "      <td>0.252940</td>\n",
              "      <td>0.237138</td>\n",
              "      <td>-0.637833</td>\n",
              "      <td>-0.811000</td>\n",
              "      <td>-0.898975</td>\n",
              "      <td>-0.919111</td>\n",
              "      <td>-0.424143</td>\n",
              "      <td>-0.520036</td>\n",
              "      <td>-0.648993</td>\n",
              "      <td>-0.655343</td>\n",
              "      <td>0.447538</td>\n",
              "      <td>0.346212</td>\n",
              "      <td>0.160946</td>\n",
              "      <td>0.130964</td>\n",
              "      <td>-0.004444</td>\n",
              "      <td>-0.102954</td>\n",
              "      <td>-0.259022</td>\n",
              "      <td>-0.276751</td>\n",
              "      <td>0.290</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.1394</td>\n",
              "      <td>0.237333</td>\n",
              "      <td>-0.454</td>\n",
              "      <td>-0.5275</td>\n",
              "      <td>-0.5208</td>\n",
              "      <td>-0.472267</td>\n",
              "      <td>-1.162</td>\n",
              "      <td>-1.3625</td>\n",
              "      <td>-1.3944</td>\n",
              "      <td>-1.315733</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.65</td>\n",
              "      <td>6.94</td>\n",
              "      <td>6.373333</td>\n",
              "      <td>14.2</td>\n",
              "      <td>14.55</td>\n",
              "      <td>15.24</td>\n",
              "      <td>15.080000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-7.379165e-01</td>\n",
              "      <td>-0.435167</td>\n",
              "      <td>-0.163444</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.628109</td>\n",
              "      <td>-0.813731</td>\n",
              "      <td>-0.841880</td>\n",
              "      <td>0.708947</td>\n",
              "      <td>0.104499</td>\n",
              "      <td>0.279822</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-08-19</td>\n",
              "      <td>-0.171277</td>\n",
              "      <td>0.482333</td>\n",
              "      <td>-0.541667</td>\n",
              "      <td>-0.369643</td>\n",
              "      <td>0.454615</td>\n",
              "      <td>0.027222</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-1.13</td>\n",
              "      <td>8.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.203597</td>\n",
              "      <td>-0.261893</td>\n",
              "      <td>-0.368735</td>\n",
              "      <td>-0.354272</td>\n",
              "      <td>0.496200</td>\n",
              "      <td>0.469350</td>\n",
              "      <td>0.261500</td>\n",
              "      <td>0.240778</td>\n",
              "      <td>-0.597000</td>\n",
              "      <td>-0.792667</td>\n",
              "      <td>-0.891067</td>\n",
              "      <td>-0.913100</td>\n",
              "      <td>-0.391929</td>\n",
              "      <td>-0.506804</td>\n",
              "      <td>-0.642679</td>\n",
              "      <td>-0.651214</td>\n",
              "      <td>0.443538</td>\n",
              "      <td>0.355654</td>\n",
              "      <td>0.171323</td>\n",
              "      <td>0.136267</td>\n",
              "      <td>0.010333</td>\n",
              "      <td>-0.091546</td>\n",
              "      <td>-0.250752</td>\n",
              "      <td>-0.272057</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.2055</td>\n",
              "      <td>0.1384</td>\n",
              "      <td>0.234667</td>\n",
              "      <td>-0.446</td>\n",
              "      <td>-0.5225</td>\n",
              "      <td>-0.5224</td>\n",
              "      <td>-0.472933</td>\n",
              "      <td>-1.122</td>\n",
              "      <td>-1.3485</td>\n",
              "      <td>-1.3930</td>\n",
              "      <td>-1.315333</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.70</td>\n",
              "      <td>6.98</td>\n",
              "      <td>6.413333</td>\n",
              "      <td>15.6</td>\n",
              "      <td>14.40</td>\n",
              "      <td>15.42</td>\n",
              "      <td>15.253333</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-7.562178e-01</td>\n",
              "      <td>-0.452487</td>\n",
              "      <td>-0.181658</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.609808</td>\n",
              "      <td>-0.803731</td>\n",
              "      <td>-0.837000</td>\n",
              "      <td>0.727062</td>\n",
              "      <td>0.178703</td>\n",
              "      <td>0.303399</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-08-22</td>\n",
              "      <td>-0.269281</td>\n",
              "      <td>0.453000</td>\n",
              "      <td>-0.545833</td>\n",
              "      <td>-0.390357</td>\n",
              "      <td>0.439231</td>\n",
              "      <td>0.009074</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>8.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.200206</td>\n",
              "      <td>-0.261100</td>\n",
              "      <td>-0.364659</td>\n",
              "      <td>-0.353129</td>\n",
              "      <td>0.492667</td>\n",
              "      <td>0.473433</td>\n",
              "      <td>0.270320</td>\n",
              "      <td>0.243996</td>\n",
              "      <td>-0.565333</td>\n",
              "      <td>-0.774125</td>\n",
              "      <td>-0.883075</td>\n",
              "      <td>-0.907089</td>\n",
              "      <td>-0.371286</td>\n",
              "      <td>-0.494054</td>\n",
              "      <td>-0.636579</td>\n",
              "      <td>-0.647219</td>\n",
              "      <td>0.446462</td>\n",
              "      <td>0.363750</td>\n",
              "      <td>0.182308</td>\n",
              "      <td>0.141226</td>\n",
              "      <td>0.022444</td>\n",
              "      <td>-0.081037</td>\n",
              "      <td>-0.242300</td>\n",
              "      <td>-0.267598</td>\n",
              "      <td>0.298</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>0.1364</td>\n",
              "      <td>0.232000</td>\n",
              "      <td>-0.446</td>\n",
              "      <td>-0.5145</td>\n",
              "      <td>-0.5238</td>\n",
              "      <td>-0.473467</td>\n",
              "      <td>-1.106</td>\n",
              "      <td>-1.3300</td>\n",
              "      <td>-1.3914</td>\n",
              "      <td>-1.314400</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.75</td>\n",
              "      <td>7.02</td>\n",
              "      <td>6.453333</td>\n",
              "      <td>17.0</td>\n",
              "      <td>14.25</td>\n",
              "      <td>15.60</td>\n",
              "      <td>15.426667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-7.745191e-01</td>\n",
              "      <td>-0.469808</td>\n",
              "      <td>-0.199872</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.591506</td>\n",
              "      <td>-0.793731</td>\n",
              "      <td>-0.832120</td>\n",
              "      <td>0.725349</td>\n",
              "      <td>0.249597</td>\n",
              "      <td>0.315674</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-08-23</td>\n",
              "      <td>-0.254736</td>\n",
              "      <td>0.439333</td>\n",
              "      <td>-0.541667</td>\n",
              "      <td>-0.408571</td>\n",
              "      <td>0.446923</td>\n",
              "      <td>0.003333</td>\n",
              "      <td>0.16</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>-1.18</td>\n",
              "      <td>8.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.198129</td>\n",
              "      <td>-0.255847</td>\n",
              "      <td>-0.358231</td>\n",
              "      <td>-0.351695</td>\n",
              "      <td>0.484800</td>\n",
              "      <td>0.476400</td>\n",
              "      <td>0.279173</td>\n",
              "      <td>0.246747</td>\n",
              "      <td>-0.547083</td>\n",
              "      <td>-0.755375</td>\n",
              "      <td>-0.874450</td>\n",
              "      <td>-0.900872</td>\n",
              "      <td>-0.366929</td>\n",
              "      <td>-0.482500</td>\n",
              "      <td>-0.630400</td>\n",
              "      <td>-0.643405</td>\n",
              "      <td>0.449538</td>\n",
              "      <td>0.372038</td>\n",
              "      <td>0.193831</td>\n",
              "      <td>0.146031</td>\n",
              "      <td>0.026185</td>\n",
              "      <td>-0.071056</td>\n",
              "      <td>-0.233548</td>\n",
              "      <td>-0.263306</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.1326</td>\n",
              "      <td>0.229067</td>\n",
              "      <td>-0.452</td>\n",
              "      <td>-0.5090</td>\n",
              "      <td>-0.5250</td>\n",
              "      <td>-0.473600</td>\n",
              "      <td>-1.118</td>\n",
              "      <td>-1.3150</td>\n",
              "      <td>-1.3908</td>\n",
              "      <td>-1.312933</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.80</td>\n",
              "      <td>7.06</td>\n",
              "      <td>6.493333</td>\n",
              "      <td>18.4</td>\n",
              "      <td>14.10</td>\n",
              "      <td>15.78</td>\n",
              "      <td>15.600000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-7.928203e-01</td>\n",
              "      <td>-0.487128</td>\n",
              "      <td>-0.218085</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.573205</td>\n",
              "      <td>-0.783731</td>\n",
              "      <td>-0.827239</td>\n",
              "      <td>0.674484</td>\n",
              "      <td>0.305586</td>\n",
              "      <td>0.318937</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>0.237706</td>\n",
              "      <td>0.176667</td>\n",
              "      <td>0.229167</td>\n",
              "      <td>0.200714</td>\n",
              "      <td>0.199231</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-0.67</td>\n",
              "      <td>0.16</td>\n",
              "      <td>2.34</td>\n",
              "      <td>6.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.224647e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.370160</td>\n",
              "      <td>0.086362</td>\n",
              "      <td>-0.287706</td>\n",
              "      <td>-0.358404</td>\n",
              "      <td>0.281333</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>-0.331640</td>\n",
              "      <td>-0.413360</td>\n",
              "      <td>0.300167</td>\n",
              "      <td>0.061917</td>\n",
              "      <td>-0.271350</td>\n",
              "      <td>-0.359117</td>\n",
              "      <td>0.382429</td>\n",
              "      <td>0.032804</td>\n",
              "      <td>-0.242721</td>\n",
              "      <td>-0.315000</td>\n",
              "      <td>0.189846</td>\n",
              "      <td>0.047212</td>\n",
              "      <td>-0.371746</td>\n",
              "      <td>-0.469215</td>\n",
              "      <td>0.289704</td>\n",
              "      <td>0.039741</td>\n",
              "      <td>-0.304844</td>\n",
              "      <td>-0.389252</td>\n",
              "      <td>-0.642</td>\n",
              "      <td>-0.6800</td>\n",
              "      <td>-0.7296</td>\n",
              "      <td>-0.748400</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.0955</td>\n",
              "      <td>-0.0174</td>\n",
              "      <td>-0.049200</td>\n",
              "      <td>2.340</td>\n",
              "      <td>2.1020</td>\n",
              "      <td>1.9738</td>\n",
              "      <td>1.914933</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>5.26</td>\n",
              "      <td>4.680000</td>\n",
              "      <td>25.8</td>\n",
              "      <td>15.30</td>\n",
              "      <td>17.08</td>\n",
              "      <td>17.053333</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.960000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.187096e-16</td>\n",
              "      <td>0.348564</td>\n",
              "      <td>0.542487</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.863731</td>\n",
              "      <td>-0.662487</td>\n",
              "      <td>0.887719</td>\n",
              "      <td>0.210070</td>\n",
              "      <td>0.266835</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>2021-07-01</td>\n",
              "      <td>0.238684</td>\n",
              "      <td>0.194000</td>\n",
              "      <td>0.207083</td>\n",
              "      <td>0.223214</td>\n",
              "      <td>0.174615</td>\n",
              "      <td>0.199815</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>0.21</td>\n",
              "      <td>2.34</td>\n",
              "      <td>6.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.224647e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.329280</td>\n",
              "      <td>0.118403</td>\n",
              "      <td>-0.272541</td>\n",
              "      <td>-0.352147</td>\n",
              "      <td>0.256600</td>\n",
              "      <td>0.054750</td>\n",
              "      <td>-0.315867</td>\n",
              "      <td>-0.406493</td>\n",
              "      <td>0.267917</td>\n",
              "      <td>0.089313</td>\n",
              "      <td>-0.256200</td>\n",
              "      <td>-0.352578</td>\n",
              "      <td>0.335214</td>\n",
              "      <td>0.064357</td>\n",
              "      <td>-0.230364</td>\n",
              "      <td>-0.308814</td>\n",
              "      <td>0.182385</td>\n",
              "      <td>0.076308</td>\n",
              "      <td>-0.352869</td>\n",
              "      <td>-0.461918</td>\n",
              "      <td>0.261630</td>\n",
              "      <td>0.070111</td>\n",
              "      <td>-0.289348</td>\n",
              "      <td>-0.382531</td>\n",
              "      <td>-0.614</td>\n",
              "      <td>-0.6645</td>\n",
              "      <td>-0.7290</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>0.178</td>\n",
              "      <td>0.1065</td>\n",
              "      <td>-0.0118</td>\n",
              "      <td>-0.047867</td>\n",
              "      <td>2.340</td>\n",
              "      <td>2.1260</td>\n",
              "      <td>1.9788</td>\n",
              "      <td>1.915467</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>5.30</td>\n",
              "      <td>4.720000</td>\n",
              "      <td>27.2</td>\n",
              "      <td>16.70</td>\n",
              "      <td>17.26</td>\n",
              "      <td>17.240000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.973333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.187096e-16</td>\n",
              "      <td>0.331244</td>\n",
              "      <td>0.529154</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.873731</td>\n",
              "      <td>-0.675820</td>\n",
              "      <td>0.887037</td>\n",
              "      <td>0.222501</td>\n",
              "      <td>0.266457</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>-0.010987</td>\n",
              "      <td>0.016000</td>\n",
              "      <td>0.063333</td>\n",
              "      <td>-0.046429</td>\n",
              "      <td>0.126923</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2.34</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.228313</td>\n",
              "      <td>0.135093</td>\n",
              "      <td>-0.259164</td>\n",
              "      <td>-0.348133</td>\n",
              "      <td>0.192533</td>\n",
              "      <td>0.075567</td>\n",
              "      <td>-0.300567</td>\n",
              "      <td>-0.400907</td>\n",
              "      <td>0.210083</td>\n",
              "      <td>0.107479</td>\n",
              "      <td>-0.241492</td>\n",
              "      <td>-0.346689</td>\n",
              "      <td>0.226500</td>\n",
              "      <td>0.081107</td>\n",
              "      <td>-0.217857</td>\n",
              "      <td>-0.305148</td>\n",
              "      <td>0.172154</td>\n",
              "      <td>0.099058</td>\n",
              "      <td>-0.335108</td>\n",
              "      <td>-0.453985</td>\n",
              "      <td>0.200333</td>\n",
              "      <td>0.089750</td>\n",
              "      <td>-0.274311</td>\n",
              "      <td>-0.376810</td>\n",
              "      <td>-0.598</td>\n",
              "      <td>-0.6475</td>\n",
              "      <td>-0.7276</td>\n",
              "      <td>-0.749733</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>-0.0048</td>\n",
              "      <td>-0.044533</td>\n",
              "      <td>2.340</td>\n",
              "      <td>2.1485</td>\n",
              "      <td>1.9834</td>\n",
              "      <td>1.916667</td>\n",
              "      <td>6.2</td>\n",
              "      <td>6.05</td>\n",
              "      <td>5.36</td>\n",
              "      <td>4.773333</td>\n",
              "      <td>22.6</td>\n",
              "      <td>16.60</td>\n",
              "      <td>16.84</td>\n",
              "      <td>17.026667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.986667</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>-2.500000e-02</td>\n",
              "      <td>0.303923</td>\n",
              "      <td>0.509154</td>\n",
              "      <td>-0.973205</td>\n",
              "      <td>-0.993301</td>\n",
              "      <td>-0.881051</td>\n",
              "      <td>-0.687367</td>\n",
              "      <td>0.887913</td>\n",
              "      <td>0.253457</td>\n",
              "      <td>0.282455</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>-0.118228</td>\n",
              "      <td>0.014667</td>\n",
              "      <td>-0.038750</td>\n",
              "      <td>-0.139643</td>\n",
              "      <td>0.131538</td>\n",
              "      <td>-0.009074</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2.40</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.139959</td>\n",
              "      <td>0.142072</td>\n",
              "      <td>-0.248550</td>\n",
              "      <td>-0.344679</td>\n",
              "      <td>0.142200</td>\n",
              "      <td>0.093800</td>\n",
              "      <td>-0.286733</td>\n",
              "      <td>-0.394516</td>\n",
              "      <td>0.150917</td>\n",
              "      <td>0.115479</td>\n",
              "      <td>-0.229800</td>\n",
              "      <td>-0.341828</td>\n",
              "      <td>0.130643</td>\n",
              "      <td>0.089929</td>\n",
              "      <td>-0.209279</td>\n",
              "      <td>-0.301771</td>\n",
              "      <td>0.162692</td>\n",
              "      <td>0.117981</td>\n",
              "      <td>-0.317592</td>\n",
              "      <td>-0.445759</td>\n",
              "      <td>0.146074</td>\n",
              "      <td>0.103435</td>\n",
              "      <td>-0.261430</td>\n",
              "      <td>-0.371099</td>\n",
              "      <td>-0.588</td>\n",
              "      <td>-0.6300</td>\n",
              "      <td>-0.7312</td>\n",
              "      <td>-0.747200</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.1335</td>\n",
              "      <td>0.0026</td>\n",
              "      <td>-0.039200</td>\n",
              "      <td>2.352</td>\n",
              "      <td>2.1735</td>\n",
              "      <td>1.9872</td>\n",
              "      <td>1.920267</td>\n",
              "      <td>6.4</td>\n",
              "      <td>6.10</td>\n",
              "      <td>5.42</td>\n",
              "      <td>4.826667</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.50</td>\n",
              "      <td>16.42</td>\n",
              "      <td>16.813333</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>0.276603</td>\n",
              "      <td>0.489154</td>\n",
              "      <td>-0.946410</td>\n",
              "      <td>-0.986603</td>\n",
              "      <td>-0.888372</td>\n",
              "      <td>-0.698914</td>\n",
              "      <td>0.858107</td>\n",
              "      <td>0.286597</td>\n",
              "      <td>0.297075</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>-0.182984</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>-0.065833</td>\n",
              "      <td>-0.126786</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>-0.003148</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>0.32</td>\n",
              "      <td>2.45</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.032838</td>\n",
              "      <td>0.143711</td>\n",
              "      <td>-0.238111</td>\n",
              "      <td>-0.341963</td>\n",
              "      <td>0.089667</td>\n",
              "      <td>0.112117</td>\n",
              "      <td>-0.271327</td>\n",
              "      <td>-0.386431</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>0.120250</td>\n",
              "      <td>-0.217150</td>\n",
              "      <td>-0.337550</td>\n",
              "      <td>0.022214</td>\n",
              "      <td>0.098536</td>\n",
              "      <td>-0.198043</td>\n",
              "      <td>-0.297681</td>\n",
              "      <td>0.152462</td>\n",
              "      <td>0.134250</td>\n",
              "      <td>-0.300238</td>\n",
              "      <td>-0.436887</td>\n",
              "      <td>0.084926</td>\n",
              "      <td>0.115731</td>\n",
              "      <td>-0.247248</td>\n",
              "      <td>-0.364706</td>\n",
              "      <td>-0.540</td>\n",
              "      <td>-0.6055</td>\n",
              "      <td>-0.7270</td>\n",
              "      <td>-0.742133</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.1510</td>\n",
              "      <td>0.0118</td>\n",
              "      <td>-0.033600</td>\n",
              "      <td>2.374</td>\n",
              "      <td>2.2030</td>\n",
              "      <td>1.9920</td>\n",
              "      <td>1.926267</td>\n",
              "      <td>6.6</td>\n",
              "      <td>6.15</td>\n",
              "      <td>5.48</td>\n",
              "      <td>4.880000</td>\n",
              "      <td>13.4</td>\n",
              "      <td>16.40</td>\n",
              "      <td>16.00</td>\n",
              "      <td>16.626667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.946667</td>\n",
              "      <td>-0.300000</td>\n",
              "      <td>-7.500000e-02</td>\n",
              "      <td>0.249282</td>\n",
              "      <td>0.469154</td>\n",
              "      <td>-0.919615</td>\n",
              "      <td>-0.979904</td>\n",
              "      <td>-0.895692</td>\n",
              "      <td>-0.710461</td>\n",
              "      <td>0.785317</td>\n",
              "      <td>0.357170</td>\n",
              "      <td>0.304734</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1256 rows × 75 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  kpler_index  ...  moving_correl_75  target\n",
              "0     2016-08-17    -0.148709  ...          0.264829   -0.06\n",
              "1     2016-08-18    -0.146644  ...          0.279822   -0.03\n",
              "2     2016-08-19    -0.171277  ...          0.303399    0.02\n",
              "3     2016-08-22    -0.269281  ...          0.315674    0.10\n",
              "4     2016-08-23    -0.254736  ...          0.318937    0.05\n",
              "...          ...          ...  ...               ...     ...\n",
              "1251  2021-06-30     0.237706  ...          0.266835    0.18\n",
              "1252  2021-07-01     0.238684  ...          0.266457    0.16\n",
              "1253  2021-07-02    -0.010987  ...          0.282455    0.14\n",
              "1254  2021-07-05    -0.118228  ...          0.297075    0.06\n",
              "1255  2021-07-06    -0.182984  ...          0.304734    0.04\n",
              "\n",
              "[1256 rows x 75 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUsVo_Si3hlH"
      },
      "source": [
        "training_data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvbAm-K04dG1"
      },
      "source": [
        "def make_centered_classification(train_data, target_col='target'):\n",
        "    \"\"\"Turns regression into discretized classfication problem\"\"\"\n",
        "    train_data_classification = train_data.copy()\n",
        "    def assing_label(x):\n",
        "        if x < -0.05:\n",
        "            return -1\n",
        "        if x < 0.05:\n",
        "            return 0\n",
        "        return 1\n",
        "    train_data_classification[target_col] = [assing_label(x) for x in train_data_classification[target_col]]\n",
        "    return train_data_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oeRdp5_W4hPK",
        "outputId": "0c00ef1b-4f15-4083-ebb3-30055242ed61"
      },
      "source": [
        "training_data_center = make_centered_classification(training_data)\n",
        "training_data_center['target'].hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f222b7359d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASA0lEQVR4nO3dfYxcV3nH8e+DTZLWFnZekBscCzsiLY0SNcSrkBap7CYUnFDFqRqoUSg2deUCaUVFUWOKqr6oVZNKaVpSBLUItaFRNmkospsQoeB4hZBwaFxCnBeFbEIo3qZ2EzvbLoSUwNM/5iwZNjvemdmZ2fXR9yOt9t5zzr33mTPj3969O3MdmYkkqS6vWOgCJEm9Z7hLUoUMd0mqkOEuSRUy3CWpQksXugCAM844I9euXdvVtt/97ndZtmxZbwvqAevqjHV1brHWZl2dmU9dBw4ceCYzXz1rZ2Yu+Nf69euzW/v27et6236yrs5YV+cWa23W1Zn51AXcny1y1csyklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUoUVx+wFJWkhrt9+1YMfeuaE/t0TwzF2SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFVo6UIXMF8HJybZsv2uBTn2U9e9fUGOK0lz8cxdkipkuEtShQx3SapQ2+EeEUsi4usRcWdZXxcR90XEeETcFhEnlfaTy/p46V/bn9IlSa10cub+QeDRpvXrgRsz83XAMWBrad8KHCvtN5ZxkqQBaivcI+Is4O3Ap8p6AJcAd5Qhu4Ary/LGsk7pv7SMlyQNSLtn7n8L/CHwo7J+OvBcZr5Y1g8Bq8vyauA7AKV/soyXJA1IZObxB0T8KnB5Zn4gIoaBDwNbgP3l0gsRsQa4OzPPi4iHgA2Zeaj0PQG8MTOfmbHfbcA2gFWrVq0fHR3t6gEcOTrJ4ee72nTezl+9omXf1NQUy5cvH2A17bGuzizWumDx1nYi1nVwYnLA1bxk3YolXc/XyMjIgcwcmq2vnQ8xvQm4IiIuB04BXgX8HbAyIpaWs/OzgIkyfgJYAxyKiKXACuDZmTvNzB3ADoChoaEcHh7u6EFNu+mW3dxwcGE+i/XU1cMt+8bGxuj2MfWTdXVmsdYFi7e2E7GuhfogJMDODcv6Ml9zXpbJzI9k5lmZuRbYBNybmVcD+4CryrDNwO6yvKesU/rvzbl+PZAk9dR83ud+LfChiBincU395tJ+M3B6af8QsH1+JUqSOtXR9YzMHAPGyvKTwEWzjPk+8I4e1CZJ6pKfUJWkChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAotzB23pBPEwYnJBbup1FPXvX1Bjqs6eOYuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRWaM9wj4pSI+FpEfCMiHo6IPyvt6yLivogYj4jbIuKk0n5yWR8v/Wv7+xAkSTO1c+b+AnBJZv4CcAGwISIuBq4HbszM1wHHgK1l/FbgWGm/sYyTJA3QnOGeDVNl9ZXlK4FLgDtK+y7gyrK8saxT+i+NiOhZxZKkObV1zT0ilkTEA8AR4B7gCeC5zHyxDDkErC7Lq4HvAJT+SeD0XhYtSTq+yMz2B0esBD4P/DGws1x6ISLWAHdn5nkR8RCwITMPlb4ngDdm5jMz9rUN2AawatWq9aOjo109gCNHJzn8fFebztv5q1e07JuammL58uUDrKY91tWZxfr6gsU7ZydiXQcnJgdczUvWrVjS9XyNjIwcyMyh2fqWdrKjzHwuIvYBvwisjIil5ez8LGCiDJsA1gCHImIpsAJ4dpZ97QB2AAwNDeXw8HAnpfzYTbfs5oaDHT2Mnnnq6uGWfWNjY3T7mPrJujqzWF9fsHjn7ESsa8v2uwZbTJOdG5b1Zb7aebfMq8sZOxHxU8CvAI8C+4CryrDNwO6yvKesU/rvzU5+PZAkzVs7pyRnArsiYgmNHwa3Z+adEfEIMBoRfwF8Hbi5jL8Z+GxEjANHgU19qFuSdBxzhntmPgi8YZb2J4GLZmn/PvCOnlQnSeqKn1CVpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoXmDPeIWBMR+yLikYh4OCI+WNpPi4h7IuLx8v3U0h4R8bGIGI+IByPiwn4/CEnST2rnzP1F4A8y81zgYuCaiDgX2A7szcxzgL1lHeAy4JzytQ34RM+rliQd15zhnplPZ+a/l+X/BR4FVgMbgV1l2C7gyrK8EfhMNuwHVkbEmT2vXJLUUmRm+4Mj1gJfBs4D/iMzV5b2AI5l5sqIuBO4LjO/Uvr2Atdm5v0z9rWNxpk9q1atWj86OtrVAzhydJLDz3e16bydv3pFy76pqSmWL18+wGraY12dWayvL1i8c3Yi1nVwYnLA1bxk3YolXc/XyMjIgcwcmq1vabs7iYjlwOeA38/M/2nkeUNmZkS0/1Oisc0OYAfA0NBQDg8Pd7L5j910y25uONj2w+ipp64ebtk3NjZGt4+pn6yrM4v19QWLd85OxLq2bL9rsMU02blhWV/mq613y0TEK2kE+y2Z+S+l+fD05Zby/UhpnwDWNG1+VmmTJA1IO++WCeBm4NHM/Jumrj3A5rK8Gdjd1P6e8q6Zi4HJzHy6hzVLkubQzu+bbwJ+EzgYEQ+Utj8CrgNuj4itwLeBd5a+LwCXA+PA94D39rRiSdKc5gz38ofRaNF96SzjE7hmnnVJkubBT6hKUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVmjPcI+LTEXEkIh5qajstIu6JiMfL91NLe0TExyJiPCIejIgL+1m8JGl27Zy57wQ2zGjbDuzNzHOAvWUd4DLgnPK1DfhEb8qUJHViznDPzC8DR2c0bwR2leVdwJVN7Z/Jhv3Ayog4s1fFSpLaE5k596CItcCdmXleWX8uM1eW5QCOZebKiLgTuC4zv1L69gLXZub9s+xzG42ze1atWrV+dHS0qwdw5Ogkh5/vatN5O3/1ipZ9U1NTLF++fIDVtMe6OrNYX1+weOfsRKzr4MTkgKt5yboVS7qer5GRkQOZOTRb39J5VQVkZkbE3D8hXr7dDmAHwNDQUA4PD3d1/Jtu2c0NB+f9MLry1NXDLfvGxsbo9jH1k3V1ZrG+vmDxztmJWNeW7XcNtpgmOzcs68t8dftumcPTl1vK9yOlfQJY0zTurNImSRqgbsN9D7C5LG8Gdje1v6e8a+ZiYDIzn55njZKkDs35+2ZE3AoMA2dExCHgT4DrgNsjYivwbeCdZfgXgMuBceB7wHv7ULMkaQ5zhntmvqtF16WzjE3gmvkWJUmaHz+hKkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVagv4R4RGyLisYgYj4jt/TiGJKm1nod7RCwBPg5cBpwLvCsizu31cSRJrfXjzP0iYDwzn8zM/wNGgY19OI4kqYWlfdjnauA7TeuHgDfOHBQR24BtZXUqIh7r8nhnAM90ue28xPXH7V6wuuZgXZ1ZrK8vcM46tSjrGrl+XnW9tlVHP8K9LZm5A9gx3/1ExP2ZOdSDknrKujpjXZ1brLVZV2f6VVc/LstMAGua1s8qbZKkAelHuP8bcE5ErIuIk4BNwJ4+HEeS1ELPL8tk5osR8bvAF4ElwKcz8+FeH6fJvC/t9Il1dca6OrdYa7OuzvSlrsjMfuxXkrSA/ISqJFXIcJekCp0Q4R4R74iIhyPiRxHR8i1DrW57UP64e19pv638obcXdZ0WEfdExOPl+6mzjBmJiAeavr4fEVeWvp0R8a2mvgsGVVcZ98OmY+9pal/I+bogIr5anu8HI+I3mvp6Ol9z3SYjIk4uj3+8zMfapr6PlPbHIuJt86mji7o+FBGPlPnZGxGvbeqb9TkdUF1bIuK/m47/2019m8vz/nhEbB5wXTc21fTNiHiuqa+f8/XpiDgSEQ+16I+I+Fip+8GIuLCpb/7zlZmL/gv4eeDngDFgqMWYJcATwNnAScA3gHNL3+3AprL8SeD9Parrr4HtZXk7cP0c408DjgI/XdZ3Alf1Yb7aqguYatG+YPMF/CxwTll+DfA0sLLX83W810vTmA8AnyzLm4DbyvK5ZfzJwLqynyUDrGuk6TX0/um6jvecDqiuLcDfz7LtacCT5fupZfnUQdU1Y/zv0XiTR1/nq+z7l4ELgYda9F8O3A0EcDFwXy/n64Q4c8/MRzNzrk+wznrbg4gI4BLgjjJuF3Blj0rbWPbX7n6vAu7OzO/16PitdFrXjy30fGXmNzPz8bL8n8AR4NU9On6zdm6T0VzvHcClZX42AqOZ+UJmfgsYL/sbSF2Zua/pNbSfxmdJ+m0+txV5G3BPZh7NzGPAPcCGBarrXcCtPTr2cWXml2mczLWyEfhMNuwHVkbEmfRovk6IcG/TbLc9WA2cDjyXmS/OaO+FVZn5dFn+L2DVHOM38fIX1l+WX8lujIiTB1zXKRFxf0Tsn75UxCKar4i4iMbZ2BNNzb2ar1avl1nHlPmYpDE/7Wzbz7qabaVx9jdttud0kHX9enl+7oiI6Q8zLor5Kpev1gH3NjX3a77a0ar2nszXgt1+YKaI+BLwM7N0fTQzdw+6nmnHq6t5JTMzIlq+r7T8RD6fxvv/p32ERsidROO9rtcCfz7Aul6bmRMRcTZwb0QcpBFgXevxfH0W2JyZPyrNXc9XjSLi3cAQ8Oam5pc9p5n5xOx76Ll/BW7NzBci4ndo/NZzyYCO3Y5NwB2Z+cOmtoWcr75aNOGemW+Z5y5a3fbgWRq/7iwtZ18d3Q7heHVFxOGIODMzny5hdOQ4u3on8PnM/EHTvqfPYl+IiH8EPjzIujJzonx/MiLGgDcAn2OB5ysiXgXcReMH+/6mfXc9X7No5zYZ02MORcRSYAWN11M/b7HR1r4j4i00fmC+OTNfmG5v8Zz2IqzmrCszn21a/RSNv7FMbzs8Y9uxHtTUVl1NNgHXNDf0cb7a0ar2nsxXTZdlZr3tQTb+QrGPxvVugM1Ar34T2FP2185+X3atrwTc9HXuK4FZ/6rej7oi4tTpyxoRcQbwJuCRhZ6v8tx9nsa1yDtm9PVyvtq5TUZzvVcB95b52QNsisa7adYB5wBfm0ctHdUVEW8A/gG4IjOPNLXP+pwOsK4zm1avAB4ty18E3lrqOxV4Kz/5G2xf6yq1vZ7GHye/2tTWz/lqxx7gPeVdMxcDk+UEpjfz1a+/FPfyC/g1GtedXgAOA18s7a8BvtA07nLgmzR+8n60qf1sGv/4xoF/Bk7uUV2nA3uBx4EvAaeV9iHgU03j1tL4afyKGdvfCxykEVL/BCwfVF3AL5Vjf6N837oY5gt4N/AD4IGmrwv6MV+zvV5oXOa5oiyfUh7/eJmPs5u2/WjZ7jHgsh6/3ueq60vl38H0/OyZ6zkdUF1/BTxcjr8PeH3Ttr9V5nEceO8g6yrrfwpcN2O7fs/XrTTe7fUDGvm1FXgf8L7SHzT+Y6MnyvGHmrad93x5+wFJqlBNl2UkSYXhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkir0/3BfmewVXyE3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCK2brXZ21zh"
      },
      "source": [
        "target = training_data_center['target']\n",
        "train = training_data_center.drop(columns=['Unnamed: 0', 'target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrJAV47e4QiY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train, \n",
        "    target, \n",
        "    train_size=0.8,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqjvoYyJ6TgO"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sikjV4je3Hlc"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=10000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
        "        \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "        \"Naive Bayes\", \"QDA\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elQVcqUP5AIh",
        "outputId": "44b6a233-0b42-4181-bcd6-39d4278fc7c2"
      },
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    score = f1_score(preds, y_test, average=\"weighted\")\n",
        "    print(f\"{name}: {score}\")\n",
        "    print(confusion_matrix(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest Neighbors: 0.37073828395050523\n",
            "[[30 21 13]\n",
            " [46 23 23]\n",
            " [35 20 41]]\n",
            "Linear SVM: 0.5363679468942626\n",
            "[[42  0 22]\n",
            " [58  0 34]\n",
            " [26  0 70]]\n",
            "RBF SVM: 0.5517241379310345\n",
            "[[ 0  0 64]\n",
            " [ 0  0 92]\n",
            " [ 0  0 96]]\n",
            "Gaussian Process: 0.5446323027653429\n",
            "[[25  8 31]\n",
            " [15 16 61]\n",
            " [ 3  9 84]]\n",
            "Decision Tree: 0.45705039667747915\n",
            "[[44 14  6]\n",
            " [45 41  6]\n",
            " [36 31 29]]\n",
            "Random Forest: 0.34840685464816284\n",
            "[[ 7  4 53]\n",
            " [24 10 58]\n",
            " [23 13 60]]\n",
            "Neural Net: 0.4356716228237387\n",
            "[[31 16 17]\n",
            " [53  5 34]\n",
            " [24  9 63]]\n",
            "AdaBoost: 0.49010780771787066\n",
            "[[ 1 11 52]\n",
            " [ 0  3 89]\n",
            " [ 9  0 87]]\n",
            "Naive Bayes: 0.37738047545979697\n",
            "[[ 9 36 19]\n",
            " [16 38 38]\n",
            " [ 6 45 45]]\n",
            "QDA: 0.4952960407288481\n",
            "[[ 0 14 50]\n",
            " [ 0 28 64]\n",
            " [ 0 19 77]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5F6kHj9-7kh"
      },
      "source": [
        "# Simple models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxbrL7OyEXFT"
      },
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vlQQXczFSNC"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiFM8b2i5m-i"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
        "\n",
        "log_reg = LogisticRegression(\n",
        "    penalty='l1',\n",
        "    solver='liblinear',\n",
        "    max_iter=1000,\n",
        "    C=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVR7og8i_VbY",
        "outputId": "bdf06145-0db1-403d-cf4f-e0ad25811abd"
      },
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "tscv = TimeSeriesSplit()\n",
        "log_reg_scores = cross_val_score(\n",
        "    log_reg, X_train, target, cv=tscv, scoring='f1_weighted', n_jobs=-1, verbose=1\n",
        ")\n",
        "log_reg_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2585882 , 0.60106572, 0.60249706, 0.44807145, 0.57357119])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe2ncDIZNArR",
        "outputId": "ae57facc-498f-41a3-c5f7-e54addd3ef56"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "rfe = RFE(LogisticRegression(\n",
        "    penalty='l1',\n",
        "    solver='liblinear',\n",
        "    max_iter=1000,\n",
        "    C=1\n",
        "))\n",
        "rfe.fit(X_train, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFE(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
              "                                 fit_intercept=True, intercept_scaling=1,\n",
              "                                 l1_ratio=None, max_iter=1000,\n",
              "                                 multi_class='auto', n_jobs=None, penalty='l1',\n",
              "                                 random_state=None, solver='liblinear',\n",
              "                                 tol=0.0001, verbose=0, warm_start=False),\n",
              "    n_features_to_select=None, step=1, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qqPwd6CNtlx",
        "outputId": "f9a6aa7c-86c9-4ddf-a208-e0b5400ad021"
      },
      "source": [
        "training_data_center.drop(columns=['target', 'Unnamed: 0']).columns[rfe.support_]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['kpler_index', 'signal_low_api', 'signal_high_sulfur', 'brent_m1m2',\n",
              "       'brent_m3m4', 'dfl', 'month', 'month_cos', 'kpler_index_SMA_5',\n",
              "       'kpler_index_SMA_20', 'kpler_index_SMA_50', 'kpler_index_SMA_75',\n",
              "       'signal_high_api_SMA_50', 'signal_high_api_SMA_75',\n",
              "       'signal_low_api_SMA_50', 'signal_low_api_SMA_75',\n",
              "       'signal_high_sulfur_SMA_50', 'signal_low_sulfur_SMA_5',\n",
              "       'signal_low_sulfur_SMA_20', 'brent_m1m2_SMA_5', 'brent_m1m2_SMA_20',\n",
              "       'brent_m3m4_SMA_5', 'brent_m3m4_SMA_20', 'brent_m3m4_SMA_50',\n",
              "       'brent_m3m4_SMA_75', 'dfl_SMA_5', 'dfl_SMA_20', 'dfl_SMA_50',\n",
              "       'month_SMA_5', 'month_SMA_20', 'month_SMA_50', 'day_SMA_5',\n",
              "       'day_SMA_50', 'day_SMA_75', 'month_sin_SMA_5', 'month_sin_SMA_75'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIi08yvZFjjG"
      },
      "source": [
        "## GPC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwvfKnnr_WD_",
        "outputId": "1f08ae5b-8697-4e0a-b71a-5c1c52af4307"
      },
      "source": [
        "gauss = GaussianProcessClassifier(1.0 * RBF(1.0), n_jobs=-1)\n",
        "gauss_scores = cross_val_score(\n",
        "    gauss, X_train, target, cv=tscv, scoring='f1_weighted', n_jobs=-1, verbose=1\n",
        ")\n",
        "gauss_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.29700729, 0.18283402, 0.35211418, 0.32822531, 0.45404228])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CTeV2ADFkpY"
      },
      "source": [
        "## NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xObdNpM-EUwB",
        "outputId": "8a334241-1941-411e-e397-cf41e9dc87c2"
      },
      "source": [
        "nn = MLPClassifier(alpha=1, max_iter=10000)\n",
        "nn_scores = cross_val_score(\n",
        "    nn, X_train, target, cv=tscv, scoring='f1_weighted', n_jobs=-1, verbose=1\n",
        ")\n",
        "nn_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.37842168, 0.34339148, 0.30283394, 0.39344307, 0.46577991])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnWidXgUG9Ml"
      },
      "source": [
        "## RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq43Dmz3GCxw",
        "outputId": "edef2aed-a258-48d1-fb17-fa465d9785ae"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
        "rf_scores = cross_val_score(\n",
        "    rf, X_train, target, cv=tscv, scoring='f1_weighted', n_jobs=-1, verbose=1\n",
        ")\n",
        "rf_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   17.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.28172274, 0.40702818, 0.08069481, 0.29320803, 0.39579351])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5eoo6JTK9x5"
      },
      "source": [
        "## XGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qio7uQ8K-wQ",
        "outputId": "99947e27-2619-4ac6-fc8b-c27bca4b7f23"
      },
      "source": [
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(max_depth=2)\n",
        "xgb_scores = cross_val_score(\n",
        "    xgb, X_train, target, cv=tscv, scoring='f1_weighted', n_jobs=-1, verbose=1\n",
        ")\n",
        "xgb_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.36741481, 0.37029299, 0.21176405, 0.30135891, 0.25203455])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfz4NXq8Ls1b"
      },
      "source": [
        "XGBClassifier?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7MTJcI5HVhA"
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGs2TdjXHzbY"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, \n",
        "    target, \n",
        "    train_size=0.8,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIre_oGmIvln"
      },
      "source": [
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "m = StackingClassifier(\n",
        "    classifiers=[\n",
        "        KNeighborsClassifier(3),\n",
        "        SVC(kernel=\"linear\", C=0.025, probability=True),\n",
        "        GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "        DecisionTreeClassifier(max_depth=5),\n",
        "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "        MLPClassifier(alpha=1, max_iter=10000),\n",
        "        AdaBoostClassifier(),\n",
        "        GaussianNB(),\n",
        "        QuadraticDiscriminantAnalysis()],\n",
        "    use_probas=True,\n",
        "    meta_classifier=LogisticRegression()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJbKJKkvI88W",
        "outputId": "6e0b748c-376e-44ad-e1f0-de19f6a7a505"
      },
      "source": [
        "m.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(average_probas=False,\n",
              "                   classifiers=[KNeighborsClassifier(algorithm='auto',\n",
              "                                                     leaf_size=30,\n",
              "                                                     metric='minkowski',\n",
              "                                                     metric_params=None,\n",
              "                                                     n_jobs=None, n_neighbors=3,\n",
              "                                                     p=2, weights='uniform'),\n",
              "                                SVC(C=0.025, break_ties=False, cache_size=200,\n",
              "                                    class_weight=None, coef0=0.0,\n",
              "                                    decision_function_shape='ovr', degree=3,\n",
              "                                    gamma='scale', kernel='linear', max_iter=-1,\n",
              "                                    probab...\n",
              "                   meta_classifier=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                      dual=False,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      intercept_scaling=1,\n",
              "                                                      l1_ratio=None,\n",
              "                                                      max_iter=100,\n",
              "                                                      multi_class='auto',\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      random_state=None,\n",
              "                                                      solver='lbfgs',\n",
              "                                                      tol=0.0001, verbose=0,\n",
              "                                                      warm_start=False),\n",
              "                   store_train_meta_features=False, use_clones=True,\n",
              "                   use_features_in_secondary=False, use_probas=True, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo76H_69Jd0Q",
        "outputId": "1732c408-9803-45f2-8d04-86c61a69581e"
      },
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "predictions = m.predict(X_test)\n",
        "f1_score(predictions, y_test, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3901005696963854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGZjuPlqJhc-",
        "outputId": "3368fe12-9630-497a-f9b6-f27d3d49a92c"
      },
      "source": [
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22, 30, 12],\n",
              "       [35, 32, 25],\n",
              "       [28, 22, 46]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLDZyAapJkUT"
      },
      "source": [
        "## Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5-nxbyHHBnR"
      },
      "source": [
        "models = [log_reg, gauss, nn, rf]\n",
        "preds = pd.DataFrame()\n",
        "for i, m in enumerate(models):\n",
        "    m.fit(X_train, y_train),\n",
        "    preds[i] = m.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "0bSoYmALIFk2",
        "outputId": "0ac9bc48-1678-4aa9-e847-b034612cdf5f"
      },
      "source": [
        "weights = [1.25, 0.5, 0.2, 0.05]\n",
        "preds['weighted_pred'] = (preds * weights).sum(axis=1) / sum(weights)\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-3d086aac89bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weighted_pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;31m# TODO: why are we passing flex=True instead of flex=not special?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;31m#  15 tests fail if we pass flex=not special instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# GH17901\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mto_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 466\u001b[0;31m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiven_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m                 )\n\u001b[1;32m    468\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 5: given 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqKjVS3uIVDo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}